{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Milestone Project 2: Skim Lit ðŸ”¥ \n",
    "\n",
    "The purpose of this notebook is to build an NLP model to make reading medical abstracts easier.\n",
    "\n",
    "The model architecture to achieve their best results can be found in the [paper](https://arxiv.org/pdf/1612.05251.pdf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm access to a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Quadro P2000 (UUID: GPU-45eb6a28-8b9a-6cc9-5299-32453fd1cd04)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data\n",
    "\n",
    "Since we'll be replicating the paper above (PubMed 200K RCT), let's download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'pubmed-rct'...\n",
      "Updating files:  61% (8/13)\n",
      "Updating files:  69% (9/13)\n",
      "Updating files:  76% (10/13)\n",
      "Updating files:  84% (11/13)\n",
      "Updating files:  92% (12/13)\n",
      "Updating files: 100% (13/13)\n",
      "Updating files: 100% (13/13), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start our experiements using the 20k dataset with numbers replaced by \"@\" sign\n",
    "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all of the filenames in the target directory\n",
    "import os\n",
    "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
    "filenames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "Now we've got some text data, it's time to become one with the data. \n",
    "\n",
    "Let's write a function to read in all of the lines of a target text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to read the lines of a document\n",
    "def get_lines(filename):\n",
    "    \"\"\"\n",
    "    Reads filename (a text filename) and returns the lines of text as a list\n",
    "\n",
    "    Args: \n",
    "        filename: a string containing the target filepath. \n",
    "\n",
    "    Returns:\n",
    "        A list of strings with one string per line from the target filename\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filename,\"r\") as f:\n",
    "        return f.readlines()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['###24293578\\n',\n",
       " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
       " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
       " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
       " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
       " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
       " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
       " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
       " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
       " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
       " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
       " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
       " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
       " '\\n',\n",
       " '###24854809\\n',\n",
       " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
       " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
       " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
       " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
       " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in the training lines\n",
    "train_lines = get_lines(data_dir+\"train.txt\") # read the lines with the training file\n",
    "train_lines[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210040"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_lines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think about how we want our data to look ...\n",
    "\n",
    "How I think our data would be best represented ...\n",
    "\n",
    "```\n",
    "[{'line_number': 0,\n",
    "   'target': 'BACKGROUND',\n",
    "   'text': \"Emotional eating is associated with overeating and the development of obesity .\\n\",\n",
    "   'total_lines': 11},\n",
    "   ...]\n",
    "```   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function which turns each of our datasets into the above format so we can continue to prepare our data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_with_line_numbers(filename):\n",
    "    \"\"\"\n",
    "    Returns a list of dictionaries of abstract line data.\n",
    "\n",
    "    Takes in a filename, reads its contents and sorts through each line, extracing things like the target label,\n",
    "    the text of the sentence, how many sentences are in the current abstract and what sentence number the target line is\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    input_lines = get_lines(filename) # get all lines from filename\n",
    "    abstract_lines = \"\" # create an empty abstract\n",
    "    abstract_samples = [] # create an empty list of abstracts\n",
    "\n",
    "    # Loop through each line\n",
    "    for line in input_lines:\n",
    "        if line.startswith(\"###\"): # check to see if this is an ID line\n",
    "            abstract_id = line\n",
    "            abstract_lines = \"\" # reset the abstract string if the line is an ID line\n",
    "        elif line.isspace(): # check to see if line is a new line\n",
    "            abstract_line_split = abstract_lines.splitlines() # split abstract into seperate lines\n",
    "\n",
    "            # Iterate through each line in a single abstract and count them\n",
    "            for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
    "                line_data = {} # create an empty dictionary for each line\n",
    "                target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
    "                line_data[\"target\"] = target_text_split[0] # get target label\n",
    "                line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
    "                line_data[\"line_number\"] = abstract_line_number # what number line does the line appear\n",
    "                line_data[\"total_lines\"] = len(abstract_line_split)-1 # how many total lines\n",
    "                abstract_samples.append(line_data) # add line data to abstract samples list\n",
    "\n",
    "        else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
    "            abstract_lines += line\n",
    "\n",
    "    return abstract_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180040 30212 30135\n"
     ]
    }
   ],
   "source": [
    "# Get the data from file and preprocess it\n",
    "train_samples = preprocess_text_with_line_numbers(data_dir+\"train.txt\")\n",
    "val_samples = preprocess_text_with_line_numbers(data_dir+\"dev.txt\")\n",
    "test_samples = preprocess_text_with_line_numbers(data_dir+\"test.txt\")\n",
    "print(len(train_samples), len(val_samples), len(test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 'OBJECTIVE',\n",
       "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       "  'line_number': 2,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       "  'line_number': 3,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       "  'line_number': 4,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       "  'line_number': 5,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       "  'line_number': 6,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       "  'line_number': 7,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       "  'line_number': 8,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'these differences remained significant at @ weeks .',\n",
       "  'line_number': 9,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
       "  'line_number': 10,\n",
       "  'total_lines': 11},\n",
       " {'target': 'CONCLUSIONS',\n",
       "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
       "  'line_number': 11,\n",
       "  'total_lines': 11},\n",
       " {'target': 'BACKGROUND',\n",
       "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 10},\n",
       " {'target': 'BACKGROUND',\n",
       "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 10}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first abstract of training data\n",
    "train_samples[:14]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that oour data is in the format of a list of dictionaries, lets turn it into a DataFrame to visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>there was a clinically relevant reduction in t...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>the mean difference between treatment arms ( @...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>further , there was a clinically relevant redu...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>these differences remained significant at @ we...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>the outcome measures in rheumatology clinical ...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>emotional eating is associated with overeating...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>yet , empirical evidence for individual ( trai...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text  \\\n",
       "0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
       "1       METHODS  a total of @ patients with primary knee oa wer...   \n",
       "2       METHODS  outcome measures included pain reduction and i...   \n",
       "3       METHODS  pain was assessed using the visual analog pain...   \n",
       "4       METHODS  secondary outcome measures included the wester...   \n",
       "5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n",
       "6       RESULTS  there was a clinically relevant reduction in t...   \n",
       "7       RESULTS  the mean difference between treatment arms ( @...   \n",
       "8       RESULTS  further , there was a clinically relevant redu...   \n",
       "9       RESULTS  these differences remained significant at @ we...   \n",
       "10      RESULTS  the outcome measures in rheumatology clinical ...   \n",
       "11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
       "12   BACKGROUND  emotional eating is associated with overeating...   \n",
       "13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n",
       "\n",
       "    line_number  total_lines  \n",
       "0             0           11  \n",
       "1             1           11  \n",
       "2             2           11  \n",
       "3             3           11  \n",
       "4             4           11  \n",
       "5             5           11  \n",
       "6             6           11  \n",
       "7             7           11  \n",
       "8             8           11  \n",
       "9             9           11  \n",
       "10           10           11  \n",
       "11           11           11  \n",
       "12            0           10  \n",
       "13            1           10  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame(train_samples)\n",
    "val_df = pd.DataFrame(val_samples)\n",
    "test_df = pd.DataFrame(test_samples)\n",
    "\n",
    "train_df.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "METHODS        59353\n",
       "RESULTS        57953\n",
       "CONCLUSIONS    27168\n",
       "BACKGROUND     21727\n",
       "OBJECTIVE      13839\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of labels in training data\n",
    "train_df.target.value_counts(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Length of different lines\n",
    "train_df.total_lines.plot.hist();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get lists of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180040, 30212, 30135)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert abstract text lines into lists\n",
    "train_sentences = train_df[\"text\"].to_list()\n",
    "val_sentences = val_df[\"text\"].to_list()\n",
    "test_sentences = test_df[\"text\"].to_list()\n",
    "len(train_sentences), len(val_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       " 'these differences remained significant at @ weeks .']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 10 lines of training\n",
    "train_sentences[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Making numerical labels (ML models require numeric labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(180040, 5), dtype=float64, numpy=\n",
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encode labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False) # we want a non-sparse matrix\n",
    "\n",
    "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1,1))\n",
    "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1,1))\n",
    "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1,1))\n",
    "\n",
    "# Check what one hot encoded labels look like\n",
    "tf.constant(train_labels_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, ..., 4, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract labels (\"target\" columns) and encode them into integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
    "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
    "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
    "\n",
    "# check what the training labels look like\n",
    "train_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class names and number of classes from LabelEncoder\n",
    "num_classes = len(label_encoder.classes_)\n",
    "class_names = label_encoder.classes_\n",
    "num_classes,class_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting a series of modelling experiments ...\n",
    "\n",
    "As usual, we're going to be trying out a bunch of different models and seeing which one works best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 0: Getting a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Naive-Bayes model using sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\",TfidfVectorizer()), # convert words to numbers\n",
    "    (\"clf\",MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(X=train_sentences,\n",
    "            y=train_labels_encoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7218323844829869"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate baseline model on validation data\n",
    "model_0.score(X=val_sentences,\n",
    "              y=val_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 3, ..., 4, 4, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions using our baseline model\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download helper function\n",
    "\n",
    "Import from `helper_functions.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.1832384482987,\n",
       " 'precision': 0.7186466952323352,\n",
       " 'recall': 0.7218323844829869,\n",
       " 'f1': 0.6989250353450294}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Functions.helper_functions import calculate_results\n",
    "\n",
    "# Calculate baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                     y_pred=baseline_preds)\n",
    "\n",
    "baseline_results                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a quick function to save model results as a (.json) file in case kernel reloads\n",
    "\n",
    "def save_model_results_json(filepath,var_to_save,file_string):\n",
    "    \"\"\"\n",
    "    This function allows you to save results from a model and store them as a (.json) file\n",
    "\n",
    "    Args:\n",
    "        filepath: destination of where you want results saved\n",
    "        var_to_save: variable you are saving\n",
    "        file_string: name of file you are saving\n",
    "    \"\"\"\n",
    "    import json\n",
    "\n",
    "    with open(filepath+\"/\"+file_string+\".json\",'w') as f:\n",
    "        json.dump(var_to_save,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out saving our model results\n",
    "from Functions.helper_functions import save_model_results_json\n",
    "\n",
    "des_path = r\"Saved Results\\09_SkimLit_nlp_milestone_project_2\" # (r) ignores the forward slash\n",
    "save_model_results_json(filepath=des_path,\n",
    "                        var_to_save=baseline_results,\n",
    "                        file_string=\"baseline_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       " 'these differences remained significant at @ weeks .']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our data (the text for deep sequence models)\n",
    "\n",
    "Before we start building deep models, we have to create vectorization and embedding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.338269273494777"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long is each sentence on average?\n",
    "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
    "avg_sent_lens = np.mean(sent_lens)\n",
    "avg_sent_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What's the distribution look like?\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sent_lens, bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long of a sentence length covers 95% of examples?\n",
    "output_seq_len = int(np.percentile(sent_lens,95))\n",
    "output_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum sequence length in the training set\n",
    "max(sent_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create text vectorizer layer\n",
    "\n",
    "We want to make a layer which maps our text from words to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many words are in our vocab (taken from paper)\n",
    "max_tokens = 68_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text vectorizer\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_tokens, # number of words in vocab\n",
    "                                    output_sequence_length=output_seq_len) # desired output of vectorized sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt text vecortizer to training sentences\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      " patients with metastatic or locally recurrent gastric adenocarcinoma ( including carcinoma of the gastro-oesophageal junction ) were randomly assigned ( @ : @ : @ ) to te , tef , or tex. .\n",
      "\n",
      "Length: 34\n",
      "\n",
      "Vectorized text: [[   12     7  1321    16  2575   857   912  3582   251  1440     4     2\n",
      "  14961  5737     9    92   123     6  3644 12344    16 16449     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# Test out text vectorizer\n",
    "import random\n",
    "target_sentence = random.choice(train_sentences)\n",
    "\n",
    "print(f\"Text:\\n {target_sentence}\")\n",
    "print(f\"\\nLength: {len(target_sentence.split())}\")\n",
    "print(f\"\\nVectorized text: {text_vectorizer([target_sentence])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 64841\n",
      "Most common words in the vocab: ['', '[UNK]', 'the', 'and', 'of']\n",
      "Least common words in the vocab: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
     ]
    }
   ],
   "source": [
    "# How many words in our training vocabulary\n",
    "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
    "print(f\"Number of words in vocab: {len(rct_20k_text_vocab)}\")\n",
    "print(f\"Most common words in the vocab: {rct_20k_text_vocab[:5]}\")\n",
    "print(f\"Least common words in the vocab: {rct_20k_text_vocab[-5:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'text_vectorization',\n",
       " 'trainable': True,\n",
       " 'batch_input_shape': (None,),\n",
       " 'dtype': 'string',\n",
       " 'max_tokens': 68000,\n",
       " 'standardize': 'lower_and_strip_punctuation',\n",
       " 'split': 'whitespace',\n",
       " 'ngrams': None,\n",
       " 'output_mode': 'int',\n",
       " 'output_sequence_length': 55,\n",
       " 'pad_to_max_tokens': False,\n",
       " 'sparse': False,\n",
       " 'ragged': False,\n",
       " 'vocabulary': None,\n",
       " 'idf_weights': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the config of text vectorizer\n",
    "text_vectorizer.get_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create custom text embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "token_embed = layers.Embedding(input_dim=len(rct_20k_text_vocab), # how many words in vocab\n",
    "                               output_dim=128, # output size\n",
    "                               mask_zero=True, # use this to handle different sizes of inputs (zeros in the data  ater tokenization)\n",
    "                               name=\"token_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence before vectorization:\n",
      " patients with metastatic or locally recurrent gastric adenocarcinoma ( including carcinoma of the gastro-oesophageal junction ) were randomly assigned ( @ : @ : @ ) to te , tef , or tex. .\n",
      "\n",
      "Sentence after vectorization (before embedding):\n",
      " [[   12     7  1321    16  2575   857   912  3582   251  1440     4     2\n",
      "  14961  5737     9    92   123     6  3644 12344    16 16449     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n",
      "\n",
      "Sentence after embedding:\n",
      " [[[ 0.02485497 -0.04774896  0.01894533 ...  0.01211883 -0.03366001\n",
      "    0.00502285]\n",
      "  [ 0.03027953 -0.02088498  0.00198078 ... -0.04741693 -0.00626361\n",
      "   -0.02111496]\n",
      "  [ 0.04799977 -0.00028559 -0.00306157 ... -0.01870388  0.00181301\n",
      "    0.01745958]\n",
      "  ...\n",
      "  [ 0.04945851 -0.01633743 -0.04171972 ... -0.0277864  -0.00997448\n",
      "    0.02594149]\n",
      "  [ 0.04945851 -0.01633743 -0.04171972 ... -0.0277864  -0.00997448\n",
      "    0.02594149]\n",
      "  [ 0.04945851 -0.01633743 -0.04171972 ... -0.0277864  -0.00997448\n",
      "    0.02594149]]]\n",
      "Embedded sentence shape: (1, 55, 128)\n"
     ]
    }
   ],
   "source": [
    "# Show example embedding\n",
    "print(f\"Sentence before vectorization:\\n {target_sentence}\\n\")\n",
    "vectorized_sentence = text_vectorizer([target_sentence])\n",
    "print(f\"Sentence after vectorization (before embedding):\\n {vectorized_sentence}\\n\")\n",
    "embedded_sentence = token_embed(vectorized_sentence)\n",
    "print(f\"Sentence after embedding:\\n {embedded_sentence}\")\n",
    "print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating datasets (making sure our data loads as fast as possible)\n",
    "\n",
    "We are going to setup our data to run as fast as possible with the `tf.data` API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn our data into TensorFlow Datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences,train_labels_one_hot))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences,val_labels_one_hot))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences,test_labels_one_hot))\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the TensorSliceDataset and Prefetch\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Conv1D with token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 55)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " token_embedding (Embedding)  (None, 55, 128)          8299648   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 55, 64)            41024     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 64)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,340,997\n",
      "Trainable params: 8,340,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create 1D conv model to process sequences\n",
    "inputs = layers.Input(shape=(1,),dtype=\"string\")\n",
    "text_vectors = text_vectorizer(inputs) # vectorize inputs\n",
    "token_embeddings = token_embed(text_vectors) # create embedding\n",
    "x = layers.Conv1D(64,kernel_size=5,padding=\"same\",activation=\"relu\")(token_embeddings)\n",
    "x = layers.GlobalAveragePooling1D()(x) # condense output of feature vector\n",
    "outputs = layers.Dense(num_classes,activation=\"softmax\")(x)\n",
    "model_1=tf.keras.Model(inputs,outputs)\n",
    "\n",
    "# Compile\n",
    "model_1.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize prefetched dataset\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180064"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of samples\n",
    "len(train_dataset)*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 17s 14ms/step - loss: 0.9088 - accuracy: 0.6431 - val_loss: 0.6826 - val_accuracy: 0.7384\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 0.6627 - accuracy: 0.7516 - val_loss: 0.6379 - val_accuracy: 0.7683\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 8s 14ms/step - loss: 0.6234 - accuracy: 0.7707 - val_loss: 0.6016 - val_accuracy: 0.7842\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history_model_1 = model_1.fit(train_dataset,\n",
    "                              steps_per_epoch=int(0.1*len(train_dataset)),\n",
    "                              epochs=3,\n",
    "                              validation_data=valid_dataset,\n",
    "                              validation_steps=int(0.1*len(valid_dataset))) # only validate on 10% of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 3s 3ms/step - loss: 0.6045 - accuracy: 0.7838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6044629216194153, 0.7837614417076111]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on the whole dataset\n",
    "model_1.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[4.0942639e-01, 1.9359028e-01, 8.6578794e-02, 2.8116983e-01,\n",
       "         2.9234646e-02],\n",
       "        [4.4269663e-01, 2.9924655e-01, 1.1934631e-02, 2.3843008e-01,\n",
       "         7.6922169e-03],\n",
       "        [1.7713809e-01, 6.6148858e-03, 2.3464300e-03, 8.1386954e-01,\n",
       "         3.1082374e-05],\n",
       "        ...,\n",
       "        [4.1354360e-06, 7.8292569e-04, 8.3112100e-04, 3.5331871e-06,\n",
       "         9.9837828e-01],\n",
       "        [5.6860905e-02, 4.9554080e-01, 8.5677162e-02, 7.3949791e-02,\n",
       "         2.8797132e-01],\n",
       "        [1.8877219e-01, 6.0346115e-01, 5.8464069e-02, 6.1223920e-02,\n",
       "         8.8078715e-02]], dtype=float32),\n",
       " (30212, 5))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions (our model predicts prediction probabilites for each class)\n",
    "model_1_pred_probs  = model_1.predict(valid_dataset)\n",
    "model_1_pred_probs, model_1_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert pred probs to class\n",
    "model_1_preds = tf.argmax(model_1_pred_probs,axis=1)\n",
    "model_1_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.3761419303588,\n",
       " 'precision': 0.7804652421572669,\n",
       " 'recall': 0.783761419303588,\n",
       " 'f1': 0.7813778593522251}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 results\n",
    "model_1_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                    y_pred=model_1_preds)\n",
    "model_1_results                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model results\n",
    "des_path = r\"Saved Results\\09_SkimLit_nlp_milestone_project_2\"\n",
    "\n",
    "save_model_results_json(filepath=des_path,\n",
    "                        var_to_save=model_1_results,\n",
    "                        file_string=\"model_1_results\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Feature extraction with pretrained token embeddings\n",
    "\n",
    "Now lets use pretrained word embeddings from TensorFlow Hub.\n",
    "\n",
    "[Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained TensorFlow Hub USE\n",
    "import tensorflow_hub as hub\n",
    "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        trainable=False,\n",
    "                                        name=\"universal_sentence_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sentence:\n",
      " enoxaparin , a low molecular weight heparin ( lmwh ) , is effective in prevention and treatment of vte .\n",
      "Sentence after embedding:\n",
      " [[-0.03472837  0.04410616 -0.00884213 -0.05817914 -0.03517761 -0.02288542\n",
      "   0.03376139 -0.03268823 -0.02496088  0.02577084  0.08984914 -0.07822113\n",
      "  -0.02414707 -0.02511222 -0.02225599 -0.02492884 -0.09498459  0.05337887\n",
      "  -0.06930715 -0.03795522 -0.01589492  0.00345909 -0.01508696 -0.07825469\n",
      "   0.03567839 -0.06235521  0.03392798  0.00377433 -0.01708131  0.04787057\n",
      "   0.03511126  0.09496349  0.07275163  0.00622412 -0.06364053 -0.03215032\n",
      "   0.01723751 -0.0139228  -0.06656957 -0.03821356 -0.01166669  0.07019842\n",
      "   0.04093083  0.03325777  0.00926508 -0.02137351 -0.00411263  0.02477811\n",
      "  -0.04063461 -0.00151334 -0.06918161  0.04112294 -0.01118631  0.01140399\n",
      "   0.0033502  -0.01957473  0.02424347  0.00779649  0.0882888  -0.02954897\n",
      "  -0.04920383  0.04075768  0.02610784  0.02199798  0.01910101  0.00534318\n",
      "   0.02752437  0.08138248 -0.03783508 -0.06643964 -0.04011044  0.02060394\n",
      "   0.02445182 -0.01236271 -0.0386107  -0.00942799 -0.04053962 -0.03889894\n",
      "   0.07813472 -0.01076175 -0.02763722  0.04817247  0.08934274  0.02200224\n",
      "   0.01312364 -0.0159688   0.04410599 -0.05102625 -0.00825367 -0.00490959\n",
      "  -0.04750594  0.04492576 -0.02057961  0.05169102  0.03120418 -0.01854615\n",
      "   0.01636452 -0.01830686 -0.02522814 -0.08483602 -0.04589789 -0.01138038\n",
      "   0.04929255  0.01461851  0.07492018 -0.07362761 -0.03934062  0.04484128\n",
      "   0.0082295   0.03899674  0.06188051 -0.03982695  0.05775175 -0.03633956\n",
      "  -0.02047658  0.0304136  -0.07032988 -0.0024933   0.00809982  0.00184628\n",
      "   0.02899111  0.03281225  0.01489246  0.07067724  0.07467963 -0.03395886\n",
      "  -0.0538748   0.08191974  0.07376223 -0.03268087 -0.04535773  0.09666632\n",
      "   0.04168487  0.03394774  0.02279949  0.02350461  0.01615482  0.05305249\n",
      "  -0.00772857  0.02788571  0.08307474  0.06569333 -0.04706571  0.02612901\n",
      "   0.04831754 -0.04279873 -0.00347116 -0.07360257 -0.04299821 -0.01980899\n",
      "   0.05728018 -0.03598672 -0.07581359 -0.0851011   0.08486634  0.07601061\n",
      "  -0.01121423 -0.02538708 -0.08347195  0.05689369 -0.04983763 -0.01784175\n",
      "  -0.07630421  0.00049401  0.08592478  0.02158748 -0.07242116 -0.01933323\n",
      "  -0.01865146  0.08242499 -0.06098818 -0.09607365 -0.0374843   0.06003568\n",
      "  -0.00229702 -0.00918207 -0.03003276  0.03359135 -0.0068621   0.03557724\n",
      "  -0.07228475 -0.05757413  0.00657507 -0.01449146  0.00357821 -0.0094878\n",
      "  -0.00033305  0.00187699 -0.03237918 -0.00432244 -0.03423104 -0.06137838\n",
      "  -0.02354496  0.05992693  0.08369587  0.01485734 -0.0216668  -0.06784948\n",
      "   0.02184278 -0.03912426  0.01047954 -0.06519176 -0.08033725  0.01256257\n",
      "  -0.03875959  0.03640004  0.0851034   0.05584998 -0.02148283 -0.05911446\n",
      "  -0.04609964 -0.04555485 -0.07917021  0.00204847 -0.02454819  0.02319568\n",
      "   0.03122913 -0.01475421 -0.04635838 -0.04338515  0.02917485  0.01797133\n",
      "  -0.04122563 -0.03678453  0.06752717  0.01944913  0.04727519  0.08322349\n",
      "   0.02225458 -0.01052948  0.04744669  0.03566448 -0.01152041  0.00883914\n",
      "   0.00821296 -0.04283267  0.02482685 -0.02314587 -0.03810624  0.08920617\n",
      "  -0.02464437  0.05570756  0.030939   -0.06775761 -0.06199811 -0.02521979\n",
      "   0.07462073 -0.00336577  0.0233088  -0.08569362 -0.03337003  0.02364523\n",
      "  -0.0096794   0.01760457 -0.01915441 -0.03373038  0.05027127 -0.05524334\n",
      "  -0.01679042 -0.02137313  0.05269997 -0.02420425 -0.05983913 -0.03676167\n",
      "  -0.0629586   0.00393694  0.05350007  0.01062301  0.04133715  0.02218316\n",
      "  -0.06436881 -0.00607166  0.01145471 -0.08167893  0.08382499  0.02346848\n",
      "   0.05279571  0.04323653  0.00500329 -0.05077995  0.02543196  0.02303677\n",
      "   0.04043504  0.03495383  0.0289348  -0.05217704  0.0092208  -0.06107141\n",
      "  -0.01667636 -0.04811759 -0.04341452  0.04581535 -0.02611841 -0.04894864\n",
      "   0.08912016 -0.02373615 -0.03605489  0.02286049  0.00875226  0.02041728\n",
      "  -0.01563172 -0.02211096 -0.0620256   0.00020012 -0.05136193  0.00643853\n",
      "   0.03587058  0.01795746  0.0035605   0.00327103  0.04239668 -0.04766515\n",
      "   0.02130155  0.03874192 -0.00264988  0.03085493  0.0542927  -0.01264588\n",
      "   0.00416648 -0.08266678 -0.05486434 -0.03184757 -0.02949863  0.0171591\n",
      "   0.03335095  0.05879122 -0.00262853 -0.05637899 -0.06383681  0.08562648\n",
      "  -0.00632902 -0.07189833 -0.00403727 -0.00573281  0.00416455 -0.02685123\n",
      "   0.00620021  0.02640379  0.00610054  0.01021298 -0.01581867  0.0655618\n",
      "  -0.00239427  0.01718428 -0.00828095 -0.09159269 -0.02097823  0.02157973\n",
      "   0.01741419  0.0313086  -0.02916422 -0.07426221 -0.0357756   0.04010457\n",
      "   0.0603337   0.06412455 -0.05964089  0.07410205  0.03071782  0.05398186\n",
      "  -0.00629813  0.0015564  -0.06838885 -0.04250913  0.04536812  0.04445053\n",
      "  -0.00964882  0.02822368 -0.03506093  0.05371626  0.03334617  0.01954187\n",
      "   0.00199807 -0.0881497   0.07016674 -0.05861415  0.05057179 -0.05766845\n",
      "  -0.06437237 -0.04088275 -0.03332417  0.0718327   0.02886124 -0.00413257\n",
      "   0.08591206 -0.0296099   0.02582626  0.06071988  0.01266122  0.00538885\n",
      "   0.02212565  0.03076425  0.00813848 -0.00838501  0.0543213  -0.01102296\n",
      "   0.08051982  0.02960834  0.0431663   0.02048663  0.07780425  0.05198797\n",
      "  -0.05711139  0.05424982  0.0403019   0.00585457  0.05188055  0.01659774\n",
      "  -0.00349207 -0.04718312 -0.03083441  0.02864247  0.00532803  0.00586767\n",
      "  -0.01362484  0.0426882   0.03773332  0.04089964  0.03525413 -0.04317362\n",
      "  -0.05951051 -0.05660086 -0.00263596 -0.05681744  0.03538458 -0.03778253\n",
      "   0.07277437  0.01368574  0.04864619  0.01844283 -0.0537872   0.00061401\n",
      "   0.02024484 -0.05958996 -0.04601246 -0.03400799 -0.02441601  0.00869422\n",
      "  -0.00691912  0.05125937 -0.0341209  -0.03221353 -0.01473727  0.05779587\n",
      "   0.06487831 -0.02960011 -0.07650381  0.04435445  0.0243319  -0.00967363\n",
      "  -0.06949629 -0.00774905  0.03389984 -0.01915114 -0.02186466 -0.06729036\n",
      "  -0.08097032 -0.06144608  0.00471     0.034643    0.04353142  0.02091651\n",
      "   0.0348561  -0.02268016  0.02059794  0.0282974  -0.07663592 -0.01081253\n",
      "   0.03190037 -0.06252136 -0.02340182  0.03885355 -0.0200377  -0.02415412\n",
      "   0.00455674  0.08152062 -0.03327054 -0.00745584  0.08418111  0.07757971\n",
      "  -0.02671678  0.04600844  0.02501275  0.03131868  0.01231533  0.01272918\n",
      "   0.06282425  0.01099731 -0.02094112  0.00666545  0.06826043  0.03287796\n",
      "   0.01826679 -0.03612826  0.03826358 -0.02724933  0.07347362  0.06038163\n",
      "   0.01981884  0.0536349  -0.04018617 -0.02954283  0.00434675  0.04260639\n",
      "   0.07287205 -0.09090138  0.02843018 -0.03346862  0.0086127   0.05040418\n",
      "  -0.04559924 -0.03014304]]\n",
      "\n",
      "Length of sentence embedding: 512\n"
     ]
    }
   ],
   "source": [
    "# Test out the pretrained embedding on a random sentence\n",
    "random_train_sentence = random.choice(train_sentences)\n",
    "print(f\"Random sentence:\\n {random_train_sentence}\")\n",
    "use_embedded_sentence = tf_hub_embedding_layer([random_train_sentence])\n",
    "print(f\"Sentence after embedding:\\n {use_embedded_sentence[:30]}\\n\")\n",
    "print(f\"Length of sentence embedding: {len(use_embedded_sentence[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and fitting a NLP feature extraction model using pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_USE_feature_extractor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " universal_sentence_encoder   (None, 512)              256797824 \n",
      " (KerasLayer)                                                    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,864,133\n",
      "Trainable params: 66,309\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a model\n",
    "inputs = layers.Input(shape=[], dtype=\"string\")\n",
    "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and embedd\n",
    "x = layers.Dense(128,activation=\"relu\")(pretrained_embedding)\n",
    "outputs = layers.Dense(5,activation=\"softmax\")(x) # create output layer\n",
    "model_2 = tf.keras.Model(inputs,outputs,name=\"model_2_USE_feature_extractor\")\n",
    "\n",
    "# Compile\n",
    "model_2.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Get a summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 11s 16ms/step - loss: 0.9221 - accuracy: 0.6462 - val_loss: 0.7976 - val_accuracy: 0.6902\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 9s 15ms/step - loss: 0.7703 - accuracy: 0.7011 - val_loss: 0.7559 - val_accuracy: 0.7055\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 9s 16ms/step - loss: 0.7556 - accuracy: 0.7104 - val_loss: 0.7422 - val_accuracy: 0.7111\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history_model_2 = model_2.fit(train_dataset,\n",
    "                              steps_per_epoch=int(0.1*len(train_dataset)),\n",
    "                              epochs=3,\n",
    "                              validation_data=valid_dataset,\n",
    "                              validation_steps=int(0.1*len(valid_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 12s 12ms/step - loss: 0.7439 - accuracy: 0.7125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7438806295394897, 0.7125314474105835]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on the whole dataset\n",
    "model_2.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 11s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.6617761e-01, 3.2933375e-01, 1.7811391e-03, 1.9677840e-01,\n",
       "        5.9292144e-03],\n",
       "       [3.3531499e-01, 5.2845496e-01, 2.6465859e-03, 1.3136126e-01,\n",
       "        2.2221417e-03],\n",
       "       [2.3849107e-01, 1.3562676e-01, 1.7420305e-02, 5.7393682e-01,\n",
       "        3.4525026e-02],\n",
       "       ...,\n",
       "       [2.1078472e-03, 5.1304828e-03, 5.7855900e-02, 7.7939348e-04,\n",
       "        9.3412638e-01],\n",
       "       [3.8375072e-03, 4.7280576e-02, 1.9503494e-01, 1.4953817e-03,\n",
       "        7.5235164e-01],\n",
       "       [2.0511489e-01, 2.5091451e-01, 4.6363994e-01, 8.3384542e-03,\n",
       "        7.1992137e-02]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "model_2_pred_probs = model_2.predict(valid_dataset)\n",
    "model_2_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 2], dtype=int64)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on labels\n",
    "model_2_preds = tf.argmax(model_2_pred_probs,axis=1)\n",
    "model_2_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 71.25314444591552,\n",
       "  'precision': 0.7126826730439386,\n",
       "  'recall': 0.7125314444591553,\n",
       "  'f1': 0.7095278665443793},\n",
       " {'accuracy': 78.3761419303588,\n",
       "  'precision': 0.7804652421572669,\n",
       "  'recall': 0.783761419303588,\n",
       "  'f1': 0.7813778593522251},\n",
       " {'accuracy': 72.1832384482987,\n",
       "  'precision': 0.7186466952323352,\n",
       "  'recall': 0.7218323844829869,\n",
       "  'f1': 0.6989250353450294})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results\n",
    "model_2_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                    y_pred=model_2_preds)\n",
    "                                    \n",
    "model_2_results, model_1_results, baseline_results                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model results \n",
    "from Functions.helper_functions import save_model_results_json\n",
    "\n",
    "des_path = r\"Saved Results\\09_SkimLit_nlp_milestone_project_2\"\n",
    "\n",
    "save_model_results_json(filepath=des_path,\n",
    "                        var_to_save=model_2_results,\n",
    "                        file_string=\"model_2_results\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Conv1D with Character Embeddings\n",
    "\n",
    "The paper which we're replicating states they used a combo of token and character level embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a character-level tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e n o x a p a r i n   ,   a   l o w   m o l e c u l a r   w e i g h t   h e p a r i n   (   l m w h   )   ,   i s   e f f e c t i v e   i n   p r e v e n t i o n   a n d   t r e a t m e n t   o f   v t e   .'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make function to split sentences into characters\n",
    "def split_chars(text):\n",
    "    return \" \".join(list(text))\n",
    "\n",
    "# Test splitting non-character level  sequence into chabracters\n",
    "split_chars(random_train_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .',\n",
       " 'a   t o t a l   o f   @   p a t i e n t s   w i t h   p r i m a r y   k n e e   o a   w e r e   r a n d o m i z e d   @ : @   ;   @   r e c e i v e d   @   m g / d a y   o f   p r e d n i s o l o n e   a n d   @   r e c e i v e d   p l a c e b o   f o r   @   w e e k s   .',\n",
       " 'o u t c o m e   m e a s u r e s   i n c l u d e d   p a i n   r e d u c t i o n   a n d   i m p r o v e m e n t   i n   f u n c t i o n   s c o r e s   a n d   s y s t e m i c   i n f l a m m a t i o n   m a r k e r s   .',\n",
       " 'p a i n   w a s   a s s e s s e d   u s i n g   t h e   v i s u a l   a n a l o g   p a i n   s c a l e   (   @ - @   m m   )   .',\n",
       " 's e c o n d a r y   o u t c o m e   m e a s u r e s   i n c l u d e d   t h e   w e s t e r n   o n t a r i o   a n d   m c m a s t e r   u n i v e r s i t i e s   o s t e o a r t h r i t i s   i n d e x   s c o r e s   ,   p a t i e n t   g l o b a l   a s s e s s m e n t   (   p g a   )   o f   t h e   s e v e r i t y   o f   k n e e   o a   ,   a n d   @ - m i n   w a l k   d i s t a n c e   (   @ m w d   )   .']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split sequence-level data splits into character-level data splots\n",
    "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
    "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
    "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
    "\n",
    "train_chars[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149.3662574983337"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the average character length?\n",
    "char_lens = [len(sentence) for sentence in train_sentences]\n",
    "mean_char_lens = np.mean(char_lens)\n",
    "mean_char_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(char_lens,bins=7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find what character length covers 95% of sequences\n",
    "output_seq_char_len = int(np.percentile(char_lens,95))\n",
    "output_seq_char_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all keyboard characters\n",
    "import string\n",
    "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create char-level token vectorizer instance\n",
    "NUM_CHAR_TOKENS = len(alphabet)+2 # add 2 for space and OOV (out of vocab()\n",
    "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,\n",
    "                                    output_sequence_length=output_seq_char_len,\n",
    "                                    name=\"char_vectorizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt character vectorizer to training character\n",
    "char_vectorizer.adapt(train_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different characters: 28\n",
      "5 most common characters: ['', '[UNK]', 'e', 't', 'i']\n",
      "5 least common characters: ['k', 'x', 'z', 'q', 'j']\n"
     ]
    }
   ],
   "source": [
    "# Check character vocab stats\n",
    "char_vocab = char_vectorizer.get_vocabulary()\n",
    "print(f\"Number of different characters: {len(char_vocab)}\")\n",
    "print(f\"5 most common characters: {char_vocab[:5]}\")\n",
    "print(f\"5 least common characters: {char_vocab[-5:]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charified text:\n",
      " a l c o h o l   w i t h d r a w a l   s y m p t o m s   w e r e   r a t e d   o n   c i w a - a r   (   c l i n i c a l   i n s t i t u t e   w i t h d r a w a l   a s s e s s m e n t   -   a l c o h o l   r e v i s e d   )   .\n",
      "\n",
      "Length of random_train_chars: 98\n",
      "\n",
      "Vectorized chars:\n",
      " [[ 5 12 11  7 13  7 12 20  4  3 13 10  8  5 20  5 12  9 19 15 14  3  7 15\n",
      "   9 20  2  8  2  8  5  3  2 10  7  6 11  4 20  5  5  8 11 12  4  6  4 11\n",
      "   5 12  4  6  9  3  4  3 16  3  2 20  4  3 13 10  8  5 20  5 12  5  9  9\n",
      "   2  9  9 15  2  6  3  5 12 11  7 13  7 12  8  2 21  4  9  2 10  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]]\n",
      "\n",
      "Length of vectorized chars: 290\n"
     ]
    }
   ],
   "source": [
    "# Test out character vectorizer\n",
    "random_train_chars = random.choice(train_chars)\n",
    "print(f\"Charified text:\\n {random_train_chars}\")\n",
    "print(f\"\\nLength of random_train_chars: {len(random_train_chars.split())}\")\n",
    "vectorized_chars = char_vectorizer([random_train_chars])\n",
    "print(f\"\\nVectorized chars:\\n {vectorized_chars}\")\n",
    "print(f\"\\nLength of vectorized chars: {len(vectorized_chars[0])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a character-level emdedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating char embedding layer\n",
    "char_embed = layers.Embedding(input_dim=len(char_vocab), # number of different charcters\n",
    "                              output_dim=25, # size of char embedding in the paper\n",
    "                              mask_zero=True,\n",
    "                              name=\"char_embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charified text:\n",
      " a l c o h o l   w i t h d r a w a l   s y m p t o m s   w e r e   r a t e d   o n   c i w a - a r   (   c l i n i c a l   i n s t i t u t e   w i t h d r a w a l   a s s e s s m e n t   -   a l c o h o l   r e v i s e d   )   .\n",
      "\n",
      "Embedded chars after vectorization and embedding:\n",
      " [[[ 0.04042384 -0.04419624  0.02340741 ... -0.04046476  0.03933522\n",
      "    0.00110926]\n",
      "  [-0.00424689 -0.01645697  0.01855883 ...  0.04269986  0.04405061\n",
      "   -0.00823249]\n",
      "  [ 0.01823986  0.03581533  0.04377511 ... -0.02364621 -0.01364471\n",
      "    0.04438882]\n",
      "  ...\n",
      "  [ 0.02922318  0.0300699   0.00887855 ... -0.03127225  0.01052431\n",
      "   -0.04162407]\n",
      "  [ 0.02922318  0.0300699   0.00887855 ... -0.03127225  0.01052431\n",
      "   -0.04162407]\n",
      "  [ 0.02922318  0.0300699   0.00887855 ... -0.03127225  0.01052431\n",
      "   -0.04162407]]]\n",
      "\n",
      "Character embedding shape: (1, 290, 25)\n"
     ]
    }
   ],
   "source": [
    "# Test our charcter embedding layer\n",
    "print(f\"Charified text:\\n {random_train_chars}\\n\")\n",
    "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
    "print(f\"Embedded chars after vectorization and embedding:\\n {char_embed_example}\\n\")\n",
    "print(f\"Character embedding shape: {char_embed_example.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Conv1D model to fit on character embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_conv1D_char_embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " char_vectorizer (TextVector  (None, 290)              0         \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " char_embed (Embedding)      (None, 290, 25)           700       \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 290, 64)           8064      \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 64)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,089\n",
      "Trainable params: 9,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a model\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "char_vectors = char_vectorizer(inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(char_embeddings)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model_3 = tf.keras.Model(inputs=inputs,\n",
    "                         outputs=outputs,\n",
    "                         name=\"model_3_conv1D_char_embedding\")\n",
    "\n",
    "# Compile\n",
    "model_3.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Get a summary\n",
    "model_3.summary()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create char level datasets\n",
    "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars,train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars,val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_char_dataset = tf.data.Dataset.from_tensor_slices((test_chars,test_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 5s 7ms/step - loss: 1.2630 - accuracy: 0.4929 - val_loss: 1.0519 - val_accuracy: 0.5745\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 4s 7ms/step - loss: 1.0089 - accuracy: 0.5954 - val_loss: 0.9458 - val_accuracy: 0.6297\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 4s 6ms/step - loss: 0.9254 - accuracy: 0.6380 - val_loss: 0.8723 - val_accuracy: 0.6626\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on chars only\n",
    "model_3_history = model_3.fit(train_char_dataset,\n",
    "                              steps_per_epoch=int(0.1*len(train_char_dataset)),\n",
    "                              epochs=3,\n",
    "                              validation_data=val_char_dataset,\n",
    "                              validation_steps=int(0.1*len(val_char_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 3s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.15621956, 0.44188607, 0.09729854, 0.25193778, 0.0526581 ],\n",
       "       [0.1509093 , 0.2844299 , 0.0126033 , 0.5307671 , 0.02129036],\n",
       "       [0.06943835, 0.17213342, 0.19663599, 0.53360957, 0.02818269],\n",
       "       ...,\n",
       "       [0.01895318, 0.05631468, 0.2978582 , 0.03497323, 0.59190065],\n",
       "       [0.02918574, 0.11337048, 0.58313113, 0.03911598, 0.2351967 ],\n",
       "       [0.4794857 , 0.23001017, 0.16727786, 0.10221418, 0.02101214]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with character model only\n",
    "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
    "model_3_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([1, 3, 3, ..., 4, 2, 0], dtype=int64)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilites to class labels\n",
    "model_3_preds = tf.argmax(model_3_pred_probs,axis=1)\n",
    "model_3_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 65.57990202568516,\n",
       " 'precision': 0.6524532410782865,\n",
       " 'recall': 0.6557990202568516,\n",
       " 'f1': 0.646736969097193}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the results\n",
    "model_3_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                    y_pred=model_3_preds)\n",
    "model_3_results                         "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! File written to destination.\n"
     ]
    }
   ],
   "source": [
    "# Saving model results\n",
    "from Functions.helper_functions import save_model_results_json\n",
    "\n",
    "des_path = r\"Saved Results\\09_SkimLit_nlp_milestone_project_2\"\n",
    "\n",
    "save_model_results_json(filepath=des_path,\n",
    "                        var_to_save=model_3_results,\n",
    "                        file_string=\"model_3_results\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Combining pretrained token embeddings + character embedding\n",
    "\n",
    "1. Create a token-level embedding (similar to `model_1`)\n",
    "2. Create a character-level model (similar to `model_3`)\n",
    "3. Combine 1 & 2 with a concatenate layer (`layer.Concatenate`)\n",
    "4. Build a series of output layers on top of 3 similar to Figure 1 in the paper\n",
    "5. Construct a model which takes token and character-level sequences as input and produces sequence label probabilities as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_token_and_char_embeddings\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " char_input (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " token_input (InputLayer)       [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " char_vectorizer (TextVectoriza  (None, 290)         0           ['char_input[0][0]']             \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " universal_sentence_encoder (Ke  (None, 512)         256797824   ['token_input[0][0]']            \n",
      " rasLayer)                                                                                        \n",
      "                                                                                                  \n",
      " char_embed (Embedding)         (None, 290, 25)      700         ['char_vectorizer[3][0]']        \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          65664       ['universal_sentence_encoder[2][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 48)          9600        ['char_embed[3][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " token_char_hybrid (Concatenate  (None, 176)         0           ['dense_8[0][0]',                \n",
      " )                                                                'bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 176)          0           ['token_char_hybrid[0][0]']      \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 128)          22656       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128)          0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 5)            645         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 256,897,089\n",
      "Trainable params: 99,265\n",
      "Non-trainable params: 256,797,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup token inputs/model\n",
    "token_inputs = layers.Input(shape=[],dtype=\"string\",name=\"token_input\")\n",
    "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
    "token_ouputs = layers.Dense(128,activation=\"relu\")(token_embeddings)\n",
    "token_model = tf.keras.Model(token_inputs,token_ouputs)\n",
    "\n",
    "# 2. Setup char inputs/model\n",
    "char_inputs=layers.Input(shape=(1,),dtype=\"string\",name=\"char_input\")\n",
    "char_vectors = char_vectorizer(char_inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embeddings) # bi-LSTM shown in figure 1. 24+24 = 48 becuase of bi-directionality\n",
    "char_model = tf.keras.Model(char_inputs,char_bi_lstm)\n",
    "\n",
    "# 3. Concatenate token and char inputs (create hybrid token embedding)\n",
    "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output,char_model.output])\n",
    "\n",
    "# 4. Create output layers - adding in Dropout\n",
    "combined_dropout = layers.Dropout(0.5)(token_char_concat) # 0.5 is 50% dropout\n",
    "combined_dense = layers.Dense(128,activation=\"relu\")(combined_dropout)\n",
    "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
    "output_layer = layers.Dense(num_classes,activation=\"softmax\")(final_dropout)\n",
    "\n",
    "# 5. Construct model with char and token inputs\n",
    "model_4 = tf.keras.Model(inputs=[token_model.input,char_model.input],\n",
    "                         outputs=output_layer,\n",
    "                         name=\"model_4_token_and_char_embeddings\")\n",
    "\n",
    "model_4.summary()                        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('tf2.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b857c820aa0d415be1b12344743bfddcf32111184ae560db226809c81026c4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
