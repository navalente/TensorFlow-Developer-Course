{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with TensorFlow Part 3: Scaling Up (Food Vision)\n",
    "\n",
    "We've seen the power of transfer learning feature extraction and fine-tuning, now it's time to scale up to all of the classes in Food101 (101 classes of food).\n",
    "\n",
    "Our goal is to beat the original Food101 paper with 10% of the training data (leveraging the power of deep learning)\n",
    "\n",
    "Our baseline to beat is 50.76% accuracy across 101 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating helper functions\n",
    "\n",
    "In previous notebooks, we've created a series of helper function to do different tasks, let's download and import them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  101 Food Classes: Working with less data\n",
    "\n",
    "Our goal is to beat the original Food101 paper with 10% of the training data, so let's download it.\n",
    "\n",
    "The data we're downloading comes from the original Food101 dataset but has been preprocessed using the `image_data_modification` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the data\n",
    "unzip_data(\"101_food_classes_10_percent.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories\n",
    "train_dir=\"101_food_classes_10_percent/train/\"\n",
    "test_dir=\"101_food_classes_10_percent/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many images/class in our dataset\n",
    "walk_through_dir(\"101_food_classes_10_percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our data loaders \n",
    "import tensorflow as tf\n",
    "IMG_SIZE=(224,224)\n",
    "BATCH_SIZE=32\n",
    "\n",
    "train_data_all_10_percent=tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                              image_size=IMG_SIZE,\n",
    "                                                                              batch_size=BATCH_SIZE,\n",
    "                                                                              label_mode=\"categorical\")\n",
    "\n",
    "test_data=tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                              image_size=IMG_SIZE,\n",
    "                                                              batch_size=BATCH_SIZE,\n",
    "                                                              label_mode=\"categorical\",\n",
    "                                                              shuffle=False) # don't shuffle test data for prediction analysis                                                                                                                                                                                                                                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a big model with transfer learning on 10% of 101 food classes\n",
    "\n",
    "Here are the steps we're going to take:\n",
    "* Create a `ModelCheckpoint` callback\n",
    "* Create a data augmentation layer to build data augmentation right into the model\n",
    "* Build a headless (no top layers) Functional EfficientNetB0 backboned-model (we'll create our own output layer)\n",
    "* Compile our model\n",
    "* Feature extract for 5 full passes (5 epochs on the train dataset and validate on 15% of the test data, to save epoch time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint callback\n",
    "checkpoint_path=\"101_food_classes_10_percent_data_model_checkpoint\"\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                       save_weights_only=True,\n",
    "                                                       monitor=\"val_accuracy\",\n",
    "                                                       save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data augmentation layer to incorporate it right into the model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "data_augmentation=tf.keras.Sequential([\n",
    "    preprocessing.RandomFlip(\"horizontal\"),\n",
    "    preprocessing.RandomZoom(0.2),\n",
    "    preprocessing.RandomHeight(0.2),\n",
    "    preprocessing.RandomWidth(0.2)\n",
    "],name=\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a headless model (no top layers) Functional EfficientNetB0 model\n",
    "\n",
    "# Input shape of the data\n",
    "input_shape=(224,224,3)\n",
    "\n",
    "# Create a frozen base model\n",
    "base_model=tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "base_model.trainable=False\n",
    "\n",
    "# Create layers\n",
    "inputs=layers.Input(shape=input_shape,name=\"input_layer\")\n",
    "x=data_augmentation(inputs)\n",
    "x=base_model(x,training=False)\n",
    "x=layers.GlobalAveragePooling2D(name=\"global_avg_pool_layer\")(x)\n",
    "outputs=layers.Dense(len(train_data_all_10_percent.class_names),activation=\"softmax\",name=\"output_layer\")(x)\n",
    "\n",
    "# Construct model\n",
    "model=tf.keras.Model(inputs,outputs)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a summary of the model we created\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model \n",
    "history_all_classes_10_percent = model.fit(train_data_all_10_percent,\n",
    "                                           epochs=5,\n",
    "                                           validation_data=test_data,\n",
    "                                           validation_steps=int(0.15*len(test_data)), # validate on only 15% of the data\n",
    "                                           callbacks=[checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the whole test dataset\n",
    "feature_extraction_results=model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the loss curves\n",
    "plot_loss_curves(history_all_classes_10_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: It appears that our model is overfitting (performing too well on the training data and not generalizing to unseen data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze all of the layers in the base model\n",
    "base_model.trainable=True\n",
    "\n",
    "# Refreeze every layer but the last 5\n",
    "for layer in base_model.layers[:-5]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompile the model with lower learning_rate\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), # learning rate lowered by 10x\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What layers in the model are trainable\n",
    "for layer in model.layers:\n",
    "    print(layer.name,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which layers are trainabale in our base model\n",
    "for layer_number,layer in enumerate(base_model.layers):\n",
    "    print(layer_number,layer.name,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune for another 5 epochs\n",
    "# model has already done 5 epochs, total number of epochs we're after (5+5 = 10)\n",
    "fine_tune_epochs = 10\n",
    "\n",
    "# Refit the model\n",
    "history_all_classes_10_percent_fine_tune = model.fit(train_data_all_10_percent,\n",
    "                                                     epochs=fine_tune_epochs,\n",
    "                                                     initial_epoch=history_all_classes_10_percent.epoch[-1],\n",
    "                                                     validation_data=test_data,\n",
    "                                                     validation_steps=int(0.15*len(test_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the whole test data\n",
    "all_classes_10_percent_fine_tune_results=model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_historys(history_all_classes_10_percent,history_all_classes_10_percent_fine_tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading our model\n",
    "\n",
    "To use our model in an external application, we'll need to save it and export it somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our fine-tuned model\n",
    "model.save(\"G:/UMass/Courses/Year_4 (2022)/TensorFlowDeveloperLocal/TensorFlow-Developer-Course/101_food_classes_10_percent_saved_big_dog_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an evaluated model\n",
    "loaded_model=tf.keras.models.load_model(\"G:/UMass/Courses/Year_4 (2022)/TensorFlowDeveloperLocal/TensorFlow-Developer-Course/101_food_classes_10_percent_saved_big_dog_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate loaded model and compare performance to pre-saved model\n",
    "loaded_model_results=loaded_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results from oour loaded_model (above) should be very similar to the results below\n",
    "all_classes_10_percent_fine_tune_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the performance of the big model across all different classes\n",
    "\n",
    "Let's make some predictions, visualize them, and then later find out which predictions were the \"most\" wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the data\n",
    "unzip_data(\"06_101_food_class_10_percent_saved_big_dog_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in saved model\n",
    "model=tf.keras.models.load_model(\"G:/UMass/Courses/Year_4 (2022)/TensorFlowDeveloperLocal/TensorFlow-Developer-Course/06_101_food_class_10_percent_saved_big_dog_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the loaded model\n",
    "results_downloaded_model=model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with model\n",
    "preds_probs = model.predict(test_data,verbose=1) # set verbosity to see how long is left"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('tf2.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b857c820aa0d415be1b12344743bfddcf32111184ae560db226809c81026c4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
